{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fedd0184",
   "metadata": {},
   "source": [
    "# Loading required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "afbfdafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pyarrow\n",
      "  Downloading pyarrow-16.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in /home/ubuntu/.local/lib/python3.10/site-packages (from pyarrow) (1.26.4)\n",
      "Installing collected packages: pyarrow\n",
      "Successfully installed pyarrow-16.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pyarrow\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#required for reading .xml files\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "#required for navigating machine's directory\n",
    "import glob\n",
    "import os.path\n",
    "\n",
    "#required for communicating with SQL database\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.exc import SQLAlchemyError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2df180d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# the postgresql address for SQL base coonection\n",
    "conn_string = 'postgresql://admin:de300SPRING2024@joker.549787090008.us-east-2.redshift-serverless.amazonaws.com:5439/dev'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12401535",
   "metadata": {},
   "source": [
    "### Utility function for writing data into the SQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "05c7e906",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_to_table(data: pd.DataFrame, table_name:str):\n",
    "    db = create_engine(conn_string)\n",
    "    conn = db.connect()\n",
    "    data.to_sql(table_name, conn, if_exists=\"replace\", index=False)\n",
    "    print(\"Done inserting to the table\")\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee295b4d",
   "metadata": {},
   "source": [
    "# Step one : Extract data from ./data/ folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d928b34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/used_car_prices2.xml\n",
      "./data/used_car_prices3.json\n",
      "./data/used_car_prices2.csv\n",
      "./data/used_car_prices3.xml\n",
      "./data/used_car_prices1.xml\n",
      "./data/used_car_prices2.json\n",
      "./data/used_car_prices3.csv\n",
      "./data/used_car_prices1.json\n",
      "./data/used_car_prices1.csv\n"
     ]
    }
   ],
   "source": [
    "all_files = glob.glob('./data/*')\n",
    "\n",
    "# Output the list of files\n",
    "for file in all_files:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798d2a39",
   "metadata": {},
   "source": [
    "### Function to extract data from one .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7837037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_csv(file_to_process: str) -> pd.DataFrame:\n",
    "    \n",
    "    df = pd.read_csv(file_to_process)\n",
    "    # drop column with na\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bc67e6-5d37-4f74-aee4-22561ebdeee8",
   "metadata": {},
   "source": [
    "### Test for extrac_from_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb70693b-633d-4ed4-9a02-b1a8d74f9f05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>car_model</th>\n",
       "      <th>year_of_manufacture</th>\n",
       "      <th>price</th>\n",
       "      <th>fuel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alto 800</td>\n",
       "      <td>2017</td>\n",
       "      <td>4253.731343</td>\n",
       "      <td>Petrol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ciaz</td>\n",
       "      <td>2015</td>\n",
       "      <td>10223.880597</td>\n",
       "      <td>Diesel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  car_model  year_of_manufacture         price    fuel\n",
       "0  alto 800                 2017   4253.731343  Petrol\n",
       "1      ciaz                 2015  10223.880597  Diesel"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = extract_from_csv(all_files[2])\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b5be00",
   "metadata": {},
   "source": [
    "### Function to extract data from one .json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fc7e59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_json(file_to_process: str) -> pd.DataFrame:\n",
    "    \n",
    "    df = pd.read_json(file_to_process,lines=True)\n",
    "    # drop column with na\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d53ccce-fa30-4ff3-a3df-6222c08a7a32",
   "metadata": {},
   "source": [
    "### Test for extract_from_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3264cf7-4c1c-4340-b46d-68a7b9669281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>car_model</th>\n",
       "      <th>year_of_manufacture</th>\n",
       "      <th>price</th>\n",
       "      <th>fuel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fortuner</td>\n",
       "      <td>2012</td>\n",
       "      <td>22238.805970</td>\n",
       "      <td>Diesel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fortuner</td>\n",
       "      <td>2015</td>\n",
       "      <td>34328.358209</td>\n",
       "      <td>Diesel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  car_model  year_of_manufacture         price    fuel\n",
       "0  fortuner                 2012  22238.805970  Diesel\n",
       "1  fortuner                 2015  34328.358209  Diesel"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = extract_from_json(all_files[1])\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810ffb74",
   "metadata": {},
   "source": [
    "### Function to extract data from one  .xml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c0c08d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_xml(file_to_process: str) -> pd.DataFrame:\n",
    "    columns = ['car_model','year_of_manufacture','price', 'fuel']\n",
    "    dataframe = pd.DataFrame(columns = columns)\n",
    "    tree = ET.parse(file_to_process)\n",
    "    root = tree.getroot()\n",
    "    for person in root:\n",
    "        car_model = person.find(\"car_model\").text\n",
    "        year_of_manufacture = int(person.find(\"year_of_manufacture\").text)\n",
    "        price = float(person.find(\"price\").text)\n",
    "        fuel = person.find(\"fuel\").text\n",
    "        sample = pd.DataFrame({\"car_model\":car_model, \"year_of_manufacture\":year_of_manufacture, \"price\":price, \"fuel\":fuel}, index = [0])\n",
    "        dataframe = pd.concat([dataframe, sample], ignore_index=True)\n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9cd9d3-e820-4731-9245-ec77ae80599f",
   "metadata": {},
   "source": [
    "### Test extract_from_xml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "37612fa6-64d9-46e8-beac-f21411ac1c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2099/2390902476.py:12: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataframe = pd.concat([dataframe, sample], ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>car_model</th>\n",
       "      <th>year_of_manufacture</th>\n",
       "      <th>price</th>\n",
       "      <th>fuel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>etios liva</td>\n",
       "      <td>2014</td>\n",
       "      <td>5895.522388</td>\n",
       "      <td>Diesel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>corolla altis</td>\n",
       "      <td>2011</td>\n",
       "      <td>6716.417910</td>\n",
       "      <td>Diesel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       car_model year_of_manufacture        price    fuel\n",
       "0     etios liva                2014  5895.522388  Diesel\n",
       "1  corolla altis                2011  6716.417910  Diesel"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = extract_from_xml(all_files[0])\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10537c6b",
   "metadata": {},
   "source": [
    "### Function to extract data from the ./data/ folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ecd9f992-c76f-4029-90a6-f6a272d67170",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract():\n",
    "    extracted_data = pd.DataFrame(columns=columns)\n",
    "    print(\"Initial shape:\", extracted_data.shape)\n",
    "    \n",
    "    print(\"Starting CSV extraction...\")\n",
    "    for csv_file in glob.glob(os.path.join(folder, \"*.csv\")):\n",
    "        print(f\"Processing {csv_file}...\")\n",
    "        extracted_data = pd.concat([extracted_data, extract_from_csv(csv_file)], ignore_index=True)\n",
    "    print(\"CSV extraction completed.\")\n",
    "\n",
    "    print(\"Starting JSON extraction...\")\n",
    "    for json_file in glob.glob(os.path.join(folder, \"*.json\")):\n",
    "        print(f\"Processing {json_file}...\")\n",
    "        extracted_data = pd.concat([extracted_data, extract_from_json(json_file)], ignore_index=True)\n",
    "    print(\"JSON extraction completed.\")\n",
    "\n",
    "    print(\"Starting XML extraction...\")\n",
    "    for xml_file in glob.glob(os.path.join(folder, \"*.xml\")):\n",
    "        print(f\"Processing {xml_file}...\")\n",
    "        extracted_data = pd.concat([extracted_data, extract_from_xml(xml_file)], ignore_index=True)\n",
    "    print(\"XML extraction completed.\")\n",
    "\n",
    "    return extracted_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8a192e",
   "metadata": {},
   "source": [
    "### Extract the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a120192e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial shape: (0, 4)\n",
      "Starting CSV extraction...\n",
      "Processing data/used_car_prices2.csv...\n",
      "Processing data/used_car_prices3.csv...\n",
      "Processing data/used_car_prices1.csv...\n",
      "CSV extraction completed.\n",
      "Starting JSON extraction...\n",
      "Processing data/used_car_prices3.json...\n",
      "Processing data/used_car_prices2.json...\n",
      "Processing data/used_car_prices1.json...\n",
      "JSON extraction completed.\n",
      "Starting XML extraction...\n",
      "Processing data/used_car_prices2.xml...\n",
      "Processing data/used_car_prices3.xml...\n",
      "Processing data/used_car_prices1.xml...\n",
      "XML extraction completed.\n",
      "Shape after loading data: (90, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2099/3779425535.py:8: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  extracted_data = pd.concat([extracted_data, extract_from_csv(csv_file)], ignore_index=True)\n",
      "/tmp/ipykernel_2099/2390902476.py:12: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataframe = pd.concat([dataframe, sample], ignore_index=True)\n",
      "/tmp/ipykernel_2099/2390902476.py:12: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataframe = pd.concat([dataframe, sample], ignore_index=True)\n",
      "/tmp/ipykernel_2099/2390902476.py:12: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataframe = pd.concat([dataframe, sample], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "columns = ['car_model','year_of_manufacture','price', 'fuel']\n",
    "folder = \"data\"\n",
    "#table_name = \"car_data\"\n",
    "\n",
    "# run\n",
    "def main():\n",
    "    data = extract()\n",
    "    #insert_to_table(data, \"car_data\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "data = extract()\n",
    "print(\"Shape after loading data:\", data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b2892f",
   "metadata": {},
   "source": [
    "# Step Two: Transformation of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8734a880",
   "metadata": {},
   "outputs": [],
   "source": [
    "staging_file = \"cars.parquet\"\n",
    "staging_data_dir = \"staging_data\"\n",
    "\n",
    "def transform(df):\n",
    "    #db = create_engine(conn_string)\n",
    "\n",
    "    #df = pd.read_sql_query(f'SELECT * FROM {table_name}',con=db)\n",
    "\n",
    "    print(f\"Shape of data before transformation {df.shape}\")\n",
    "\n",
    "    # Truncate price with 2 decimal places\n",
    "    df['price'] = np.trunc(df['price'] * 100) / 100\n",
    "    \n",
    "\n",
    "    # Remove duplicates based on car_model, keep the first occurrence\n",
    "    df = df.drop_duplicates(subset=['car_model'], keep='first')\n",
    "    \n",
    "    \n",
    "    print(f\"Shape of data after transformation {df.shape}\")\n",
    "\n",
    "    # write to parquet\n",
    "    if not os.path.exists(staging_data_dir):\n",
    "        os.makedirs(staging_data_dir)\n",
    "    df.to_parquet(os.path.join(staging_data_dir, staging_file))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce56103c-cdfb-472f-9faa-3d2e02649d45",
   "metadata": {},
   "source": [
    "### Transforming the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "17b22621-6255-40b4-be72-855029a6df1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data before transformation (90, 4)\n",
      "Shape of data after transformation (25, 4)\n"
     ]
    }
   ],
   "source": [
    "transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d995c7",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Step Three : Loading data for further modeling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c20ccef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read from the .parquet file\n",
    "\n",
    "def load() -> pd.DataFrame:\n",
    "    data = pd.DataFrame()\n",
    "    for parquet_file in glob.glob(os.path.join(staging_data_dir, \"*.parquet\")):\n",
    "        data = pd.concat([pd.read_parquet(parquet_file),data])\n",
    "\n",
    "    #insert_to_table(data, table_name)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed043873-99a2-43d1-9b45-36689e4affd5",
   "metadata": {},
   "source": [
    "### Check the data head & shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1a727c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  car_model  year_of_manufacture     price    fuel\n",
      "0  alto 800                 2017   4253.72  Petrol\n",
      "1      ciaz                 2015  10223.87  Diesel\n",
      "3    ertiga                 2015   9104.46  Petrol\n",
      "4     dzire                 2009   3358.20  Petrol\n",
      "8   wagon r                 2015   4850.74     CNG\n",
      "(25, 4)\n"
     ]
    }
   ],
   "source": [
    "data = load()\n",
    "print(data.head())\n",
    "print(data.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
